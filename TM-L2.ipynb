{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will implement and evaluate a simple system for information extraction. The task of the system is to read sentences and extract pairs of the form $(x, y)$, where $x$&nbsp;is a string denoting a person, $y$&nbsp;is a string denoting an organisation, and $x$ is the &lsquo;leader&rsquo; of&nbsp;$y$. Consider the following example sentence:\n",
    "\n",
    "<blockquote>\n",
    "Mr. Obama also selected Lisa Jackson to head the Environmental Protection Agency.\n",
    "</blockquote>\n",
    "\n",
    "From this sentence the system should extract the pair\n",
    "```\n",
    "(\"Lisa Jackson\", \"Environmental Protection Agency\")\n",
    "```\n",
    "\n",
    "The system will have to solve the following sub-tasks:\n",
    "* entity extraction &ndash; identifying mentions of person and organisation entities in text\n",
    "* relation extraction &ndash; identifying instances of the &lsquo;is-leader-of&rsquo; relation\n",
    "\n",
    "The data set for the lab consists of 62,010&nbsp;sentences from the [Groningen Meaning Bank](http://gmb.let.rug.nl) (release 2.2.0), an open corpus of English. To analyse the sentences you will use [spaCy](https://spacy.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first cell imports the Python module required for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell imports spaCy and loads its English language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and gold standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is contained in the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"/home/TDDE16/labs/l2/data/gmb.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tm2` module defines a function `read_data` that returns an iterator over the lines in a file. You should use this function to read the data for this lab. Use the optional argument `n` to restrict the iteration to the first few lines of the file. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked assailants with grenades and automatic weapons attacked a wedding party in southeastern Turkey, killing 45 people and wounding at least six others.\n",
      "Turkish officials said the attack occurred Monday in the village of Bilge about 600 kilometers from Ankara.\n",
      "The wounded were taken to the hospital in the nearby city of Mardin.\n"
     ]
    }
   ],
   "source": [
    "for sentence in tm2.read_data(data_file, n=3):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the raw data, we also provide you with a gold standard of entity pairs that your system should be able to extract. The following code loads these pairs from the file `gold.txt` and adds them to the set `gold`. Each pair is augmented with the identifier of the sentence (line number in the data file) which it was extracted from. Note that the sentence (line) numbering starts at index&nbsp;0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_file = \"/home/TDDE16/labs/l2/data/gold.txt\"\n",
    "\n",
    "gold = set()\n",
    "with open(gold_file) as fp:\n",
    "    for line in fp:\n",
    "        columns = line.rstrip().split('\\t')\n",
    "        gold.add((int(columns[0]), columns[1], columns[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code prints the 10&nbsp;first pairs from the gold standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802\tAli Zardari\tPakistan People 's Party\n",
      "2297\tAbdul Aziz al-Hakim\tSupreme Council\n",
      "4823\tSlavkov\tBulgarian National Olympic Committee\n",
      "7902\tMr. Hakim\tSupreme Council\n",
      "8206\tJ. Patrick Boyle\tAmerican Meat Institute\n",
      "8633\tAli Rodriguez\tPetroleos de Venezuela\n",
      "9004\tForeign Minister Joschka Fischer\tGreen Party\n",
      "11021\tKhalaf\tal-Qaida\n",
      "11259\tJoseph Domenech\tU.N. 's Food and Agricultural Organization\n",
      "13043\tDavid Petraeus\tU.S. Central Command\n"
     ]
    }
   ],
   "source": [
    "for i, person, org in sorted(gold)[:10]:\n",
    "    print(\"{}\\t{}\\t{}\".format(i, person, org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should take a moment to have a look at the data file and see these pairs in the context of the sentence they were extracted from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list()\n",
    "for sentence in tm2.read_data(data_file, n=682):\n",
    "    sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Araujo said Mr. Chavez and the leftist observers came to criticize the government and defend the guerrillas.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got set)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a5f00c95e117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(sorted(gold))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/732A92/labs/environment/lib/python3.4/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    338\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[1;32m    339\u001b[0m                                                 max_length=self.max_length))\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/732A92/labs/environment/lib/python3.4/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got set)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the entity extraction part of your system, you do not need to do much, as you can use the full natural language processing power built into spaCy. The following code extracts the entities from the first 5&nbsp;sentences of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP\t1\t2\tORG\n",
      "Robert Dudley\t3\t5\tPERSON\n",
      "Russia\t10\t11\tGPE\n",
      "next week\t11\t13\tDATE\n",
      "first\t15\t16\tORDINAL\n",
      "2008\t22\t23\tDATE\n",
      "BP\t28\t29\tORG\n",
      "Russian\t31\t32\tNORP\n",
      "TNK\t33\t34\tORG\n",
      "BP\t35\t36\tORG\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(nlp.pipe(tm2.read_data(data_file, n=370))):\n",
    "    if i == 361:\n",
    "        for ent in doc.ents:\n",
    "            print(\"{}\\t{}\\t{}\\t{}\".format(ent.text, ent.start, ent.end, ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the [section about named entities](https://spacy.io/usage/linguistic-features#section-named-entities) from spaCy&rsquo;s documentation to get some background on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Extract relevant pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first problem that you will have to solve is to identify pairs of entities that are in the &lsquo;is-leader-of&rsquo; relation, as in the example above. There are many ways to do this, but for this lab it suffices to implement the strategy outlined in the section on [Relation Extraction](http://www.nltk.org/book/ch07.html#relation-extraction) in the book by Bird, Klein, and Loper (2009):\n",
    "\n",
    "* look for all triples of the form $(x, \\alpha, y)$ where $x$ and $y$ denote named entities of type *person* and *organisation*, respectively, and $\\alpha$ is the intervening text\n",
    "* write a regular expression to match just those instances of $\\alpha$ that express the &lsquo;is-leader-of&rsquo; relation\n",
    "\n",
    "You can restrict your attention to adjacent pairs of entities &ndash; that is, cases where $x$ precedes $y$ and $\\alpha$ does not contain other named entities.\n",
    "\n",
    "\n",
    "Write a function `extract` that takes an analysed sentence (represented as a spaCy [`Doc`](https://spacy.io/api/doc) object) and yields pairs $(x, y)$ of strings representing entity mentions predicted to be in the &lsquo;is-leader-of&rsquo; relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract(doc):\n",
    "    synonyms = nlp(u'leader chief director officer boss president king')\n",
    "    j = -1\n",
    "    for token1 in doc:\n",
    "        j = j+1 # position of the token in the word\n",
    "        for token2 in synonyms:\n",
    "            if token1.text == token2.text: \n",
    "                    print(i,j)\n",
    "                    x = list()\n",
    "                    y = list()\n",
    "                    between_start = 0\n",
    "                    between_end = 0\n",
    "                    #print(doc.ents)\n",
    "                    for ent in doc.ents:\n",
    "                        between_text = str()\n",
    "                        if ent.label_ == \"PERSON\" and ent.end < j:\n",
    "                            between_start = ent.end+1\n",
    "                            x.append(ent.text)\n",
    "                        if (between_start > 0 and ent.label_ == \"ORG\" and ent.start > j):\n",
    "                            between_end = ent.start -1\n",
    "                            y.append(ent.text)\n",
    "                            between_text = doc[between_start:between_end]\n",
    "                            #result = result + ((i,x[0],between_text,y[0]),)\n",
    "                            result = result + ((i,x[0],y[0]),)\n",
    "    return(result)\n",
    "    # TODO: Replace the following line with your own code\n",
    "    #return tm2.extract(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BP, Robert Dudley, Russia, next week, first, 2008, BP, Russian, TNK, BP)\n"
     ]
    }
   ],
   "source": [
    "result = ()\n",
    "for i, doc in enumerate(nlp.pipe(tm2.read_data(data_file, n=1000))):\n",
    "    if i == 361:\n",
    "        x = list()\n",
    "        y = list()\n",
    "        between_start = 0\n",
    "        between_end = 0\n",
    "        print(doc.ents)\n",
    "        for ent in doc.ents:\n",
    "            between_text = str()\n",
    "            if ent.label_ == \"PERSON\" :\n",
    "                between_start = ent.end+1\n",
    "                x.append(ent.text)\n",
    "            if (between_start > 0 and ent.label_ == \"ORG\"):\n",
    "                between_end = ent.start -1\n",
    "                y.append(ent.text)\n",
    "                between_text = doc[between_start:between_end]\n",
    "                result = result + ((i,x[0],between_text,y[0]),)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 1\n",
      "(the International Atomic Energy Agency, Mohamed ElBaradei, the Nobel Peace Prize)\n",
      "63 4\n",
      "(Mohamed ElBaradei, Tuesday, Arab)\n",
      "124 5\n",
      "(Jose Manuel Barroso, Monday)\n",
      "141 9\n",
      "(Palestinian, Israeli, Moshe Yaalon, the Gaza Strip, Palestinian)\n",
      "149 2\n",
      "(Iranian, Bush, Iran, U.S., one)\n",
      "149 19\n",
      "(Iranian, Bush, Iran, U.S., one)\n",
      "153 3\n",
      "(EU, Javier Solana, Tehran, later this week)\n",
      "166 1\n",
      "(the Portuguese Football Federation, Portugal, Asian, last weekend's)\n",
      "176 6\n",
      "(Burma, Independence Day, this week)\n",
      "182 13\n",
      "()\n",
      "207 21\n",
      "(8:20 am, Rugova, European Union, Javier Solana)\n",
      "210 1\n",
      "()\n",
      "218 18\n",
      "(Venezuelans,)\n",
      "220 12\n",
      "()\n",
      "283 3\n",
      "(Michael Green, Asian, the U.S. National Security Council, Bush, Pyongyang)\n",
      "291 3\n",
      "(Hamas, Islamic, Israel, the end of this year)\n",
      "306 1\n",
      "(Palestinian, Mahmoud Abbas, first, Israel, Jewish, the Gaza Strip, earlier this month)\n",
      "310 14\n",
      "(Pakistan, Taleban, U.S, Afghanistan)\n",
      "362 4\n",
      "(Dudley, TNK, BP, Moscow, BP, Tony Hayward)\n",
      "362 18\n",
      "(Dudley, TNK, BP, Moscow, BP, Tony Hayward)\n",
      "376 4\n",
      "(Friday, Senate, January 9, Justice, Sandra Day O'Connor)\n",
      "408 5\n",
      "(Friday, Togo, George Dahoun Gignor, VOA, Gnassingbe)\n",
      "408 28\n",
      "(Friday, Togo, George Dahoun Gignor, VOA, Gnassingbe)\n",
      "432 3\n",
      "(Tibet, Burma, Buddhist)\n",
      "451 3\n",
      "(U.N, Peter Erben, Thursday, 6.6 million, first, more than 30 years)\n",
      "451 5\n",
      "(U.N, Peter Erben, Thursday, 6.6 million, first, more than 30 years)\n",
      "466 12\n",
      "(Clinton, Bill)\n",
      "507 1\n",
      "(October 30 - the day, Ivory Coast)\n",
      "510 27\n",
      "(United Nations, Kofi Annan, Burma, Aung San Suu Kyi, another six months)\n",
      "573 8\n",
      "(Reynaldo Ramos,)\n",
      "615 13\n",
      "(Wednesday, third, Christian, Democratic, Angela Merkel, Gerhard Schroeder, Social Democrats)\n",
      "653 7\n",
      "(Senate, Harry Reid, Ronald Reagan, O'Connor)\n",
      "656 17\n",
      "(Bush, Senate, Democrats, earlier this year, U.S.)\n",
      "669 9\n",
      "(Wednesday, North Korea's, Kim Jong il, China, Chinese, Hu Jintao)\n",
      "734 16\n",
      "(2, Ayman al-Zawahiri, U.S., Muslim)\n",
      "736 21\n",
      "(Monday, Viktor Yanukovych, Russian Party, Regions)\n",
      "742 22\n",
      "(Iran, U.N., Iranian, Israel)\n",
      "746 1\n",
      "(Palestinian, Saeb Erekat, Palestinians, Israel)\n",
      "748 9\n",
      "(Friday, the U.N. Security Council, Iranian)\n",
      "773 6\n",
      "(Tuesday, OPEC, Abdullah, Badri)\n",
      "788 3\n",
      "(Claudia Annyaso, the U.S. Embassy, Abuja, VOA Friday, U.S., Lagos, U.S., Nigerian)\n",
      "789 1\n",
      "()\n",
      "791 7\n",
      "(al-Qaida, Osama Bin Laden, Nigeria)\n",
      "794 2\n",
      "(Gabon, El Hadj Omar BONGO, four decades)\n",
      "798 14\n",
      "(August 2009, Ali Ben BONGO)\n",
      "802 4\n",
      "(Asif Ali Zardari, the Pakistan People's Party, the Kashmir region, two)\n",
      "896 2\n",
      "(Pakistani, more than 73,000)\n",
      "994 2\n",
      "(84, later this month, recent weeks, 2006)\n"
     ]
    }
   ],
   "source": [
    "result = ()\n",
    "for i, doc in enumerate(nlp.pipe(tm2.read_data(data_file, n=1000))):\n",
    "    #synonyms = [\"leader\",\"chief\",\"director\",\"officer\",\"boss\",\"president\",\"king\"]\n",
    "    synonyms = nlp(u'leader chief director officer boss president king')\n",
    "    j = -1\n",
    "    for token1 in doc:\n",
    "        j = j+1 # position of the token in the word\n",
    "        for token2 in synonyms:\n",
    "            if token1.text == token2.text: \n",
    "                    print(i,j)\n",
    "                    x = list()\n",
    "                    y = list()\n",
    "                    between_start = 0\n",
    "                    between_end = 0\n",
    "                    #print(doc.ents)\n",
    "                    for ent in doc.ents:\n",
    "                        between_text = str()\n",
    "                        if ent.label_ == \"PERSON\" and ent.end < j:\n",
    "                            between_start = ent.end+1\n",
    "                            x.append(ent.text)\n",
    "                        if (between_start > 0 and ent.label_ == \"ORG\" and ent.start > j):\n",
    "                            between_end = ent.start -1\n",
    "                            y.append(ent.text)\n",
    "                            between_text = doc[between_start:between_end]\n",
    "                            result = result + ((i,x[0],between_text,y[0]),)\n",
    "#     lower_doc = [word.word for word in doc]\n",
    "#     print(\"lower_doc \",lower_doc)\n",
    "#     for word in synonyms:\n",
    "#         a = r'(.*)' + word + '(.*?) .*'\n",
    "#         print(a)\n",
    "#         matchOBj = re.match(a,lower_doc)\n",
    "#         print(matchOBj)\n",
    "# print(result)\n",
    "# sentences[361]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "final_result = ()\n",
    "for item in result:\n",
    "    a = re.match(r'(.*) of (.*?) .*',str(item[2]))\n",
    "    b = re.match(r'(.*) from (.*?) .*',str(item[2]))\n",
    "    #print(item[2])\n",
    "    #print(\"matched:\", a, b)\n",
    "    if a is not None or b is not None:\n",
    "        final_result = final_result + ((item[1],item[3]),)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((283,\n",
       "  'Michael Green',\n",
       "  director for Asian affairs,\n",
       "  'the U.S. National Security Council'),\n",
       " (736, 'Viktor Yanukovych', the leader of the opposition, 'Russian Party'),\n",
       " (802, 'Asif Ali Zardari', leader, \"the Pakistan People's Party\"))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[48]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows how your function is supposed to be used. The code prints out the extracted pairs for the first 1,000&nbsp;sentences in the data. It additionally numbers each pair with the sentence identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 'Kofi Annan', Haiti is at a critical juncture, as the country prepares for its first set of elections since the ouster of, 'Jean-Bertrand Aristide')\n",
      "9\tKofi Annan\tJean-Bertrand Aristide\n",
      "(42, 'Ahmad', who are members of a pro-Syrian Islamic militant group, 'Al-Ahbash')\n",
      "42\tAhmad\tAl-Ahbash\n",
      "(638, 'Hassan', Iraqi operations of the international, 'CARE')\n",
      "638\tHassan\tCARE\n",
      "(681, 'Chavez', the observers to oversee the release of three hostages held, 'the Revolutionary Armed Forces of Colombia')\n",
      "(681, 'Chavez', the observers to oversee the release of three hostages held by the Revolutionary Armed Forces of Colombia, 'the Revolutionary Armed Forces of Colombia')\n",
      "681\tChavez\tthe Revolutionary Armed Forces of Colombia\n",
      "681\tChavez\tthe Revolutionary Armed Forces of Colombia\n",
      "(736, 'Viktor Yanukovych', the leader of the opposition, 'Russian Party')\n",
      "736\tViktor Yanukovych\tRussian Party\n",
      "(761, 'Andy Roddick', claimed the remaining qualifying spots for the Association of Tennis Professionals (ATP, 'Tomas Berdych')\n",
      "761\tAndy Roddick\tTomas Berdych\n",
      "(873, 'Ould Hamma', sentenced in July to 12 years in prison for organizing the kidnapping of the aid workers and for handing them over to, 'al-Qaida')\n",
      "(873, 'Ould Hamma', sentenced in July to 12 years in prison for organizing the kidnapping of the aid workers and for handing them over to an al-Qaida-linked group in the region, 'al-Qaida')\n",
      "873\tOuld Hamma\tal-Qaida\n",
      "873\tOuld Hamma\tal-Qaida\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(nlp.pipe(tm2.read_data(data_file, n=1000))):\n",
    "    for person, org in extract(doc):\n",
    "        print(\"{}\\t{}\\t{}\".format(i, person, org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you feel confident that your `extract` function does what it is supposed to do, execute the following cell to extract the entities from the full data set. Note that this will take several minutes (remember that we are processing 62k sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = set()\n",
    "for i, doc in enumerate(nlp.pipe(tm2.read_data(data_file))):\n",
    "    for person, org in extract(doc):\n",
    "        extracted.add((i, person, org))\n",
    "    print('\\rProcessed {} sentences ...'.format(i+1), end='', flush=True)\n",
    "print(' done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the above cell, all extracted id-string-string triples are in the set `extracted`. The code in the next cell will print the first 10&nbsp;triples in this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, person, org in sorted(extracted)[:10]:\n",
    "    print(\"{}\\t{}\\t{}\".format(i, person, org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Evaluate your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have an extractor, but how good is it? Your task now is to write code that computes the precision, recall, and F1 measure of your extractor relative to the gold standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reference, predicted):\n",
    "    \"\"\"Print out the precision, recall, and F1 for the id-entity-entity\n",
    "    triples in the set `predicted`, given the triples in the reference set.\n",
    "    \n",
    "    Args:\n",
    "        reference: The reference set of triples.\n",
    "        predicted: The set of predicted triples.\n",
    "    Returns:\n",
    "        Nothing, but prints out precision, recall, and F1.\n",
    "    \"\"\"\n",
    "    # TODO: Replace the next line with your own code\n",
    "    tm2.evaluate(reference, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows how your function is intended to be used, as well as the suggested output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gold, extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Entity resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results of your quantitative evaluation, you will realise that your extractor (probably) does a rather poor job in matching the gold standard. One reason for this is that the NLP preprocessing is not perfect (spaCy was not trained on the annotations in the Groningen Meaning Bank), and that the approach of using regular expressions for relation extraction is rather naive.\n",
    "\n",
    "Another reason however is that the current version of your system does not include a component for *entity resolution*. To give an example, your system does not realise that the strings `David Petraeus` and `General David Petraeus` refer to the same entity.\n",
    "\n",
    "While writing a &lsquo;real&rsquo; entity resolver is beyond the scope of this assignment, we ask you to &lsquo;fake&rsquo; such a resolver. More specifically, you should implement a function `normalise` that takes an entity mention (a string) as its input and rewrites it to the form used in the gold standard. While this is &lsquo;cheating&rsquo;, it allows you to assess the performance of a more realistic system, and helps to illustrate that information extraction can be very domain-specific.\n",
    "\n",
    "The following cell contains skeleton code for the `normalise` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(text):\n",
    "    if text == \"David Petraeus\":\n",
    "        return \"General David Petraeus\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows how `normalise` is intended to be used. Each triple in the set `extracted` is transformed by feeding the two entity mentions into the `normalise` function. The normalised triples are then added to a new set `extracted_normalised`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_normalised = set()\n",
    "for triple in extracted:\n",
    "    extracted_normalised.add((triple[0], normalise(triple[1]), normalise(triple[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass the assignment, you should add enough normalisation rules to `normalise` to achieve a recall of at least 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(gold, extracted_normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your last task in this assignment is to do a qualitative error analysis of your information extraction system. You can do this either by writing code or by manual work (inspecting the data file), or mix the two strategies. You can also use the visualisation tools provided by spaCy. For example, the following code cell visualises the output of the named entity recogniser for the given input sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "sentence = u'Slavkov will lose his position as head of the Bulgarian National Olympic Committee.'\n",
    "\n",
    "displacy.render(nlp(sentence), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case, you should enter your pairs in the provided text boxes. Use the triple format shown above, where for each pair you also specify the sentence id (line number in the data file) from which the instance was extracted.\n",
    "\n",
    "### Recall-related errors (false negatives)\n",
    "\n",
    "By tuning the `normalise` function, you can deal with some of the recall-related mistakes that your system makes. Other recall-related errors cannot be fixed in this way. To illustrate this, find at least 5&nbsp;entity pairs in the gold standard that your system still does not identify correctly, and enter them into the text box below. For each example, provide a brief explanation of what goes wrong. Try to find examples that illustrate different types of errors."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentence_id    entity 1    entity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter your explanations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-related errors (false positives)\n",
    "\n",
    "Next, provide at least 5 entity pairs that represent false positives of your system. Explain what goes wrong."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentence_id    entity 1    entity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter your explanations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incompleteness of the gold standard\n",
    "\n",
    "You may have noticed that some of your system&rsquo;s false positives are actually &lsquo;correct&rsquo;. This can happen because, while each entity pair in the gold standard has been manually checked for correctness, no check has been made that the gold standard contains all relevant pairs. Find at least 5&nbsp;entity pairs in the data that are valid instances of the &lsquo;is-leader-of&rsquo; relation (according to your subjective judgement) but that are not contained in the gold standard."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentence_id    entity 1    entity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you find any examples that you did not find when looking for false positives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
